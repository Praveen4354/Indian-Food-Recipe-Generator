# Recipe Generator

![Recipe Generator UI](https://via.placeholder.com/800x400.png?text=Recipe+Generator+UI) <!-- Replace with actual screenshot if available -->

A Streamlit web application that recommends recipes based on user-input ingredients and difficulty level, using a machine learning model trained on a dataset scraped from BBC Good Food. Users can enter ingredients (e.g., "sugar, butter"), select a difficulty (Easy, Medium, Hard), and view recipe details with images. The project includes web scraping to collect recipes, model training for ranking, and a modern UI with recipe cards.

## Table of Contents
- [Features](#features)
- [Repository Structure](#repository-structure)
- [Dataset](#dataset)
- [Model Training](#model-training)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)

## Features
- **Recipe Recommendations**: Input ingredients and difficulty to get up to 3 matching recipes with details (title, ingredients, instructions, prep time, cook time, serves, difficulty).
- **Web Scraping**: Collects recipe data from BBC Good Food using `web_scraping.py`.
- **Machine Learning**: Trains a Keras model to rank recipes based on ingredient encodings.
- **Modern UI**: Streamlit interface with recipe cards, bold labels, and images.
- **GitHub Integration**: Option to save and push trained model to GitHub.

## Repository Structure
- **`app.py`**: Main Streamlit application for recipe generation, model training, and GitHub pushing.
- **`bbcgoodfood_recipes2.json`**: Dataset of recipes scraped from BBC Good Food (fields: Title, Image, Ingredients, Method Steps, Prep Time, Cook Time, Serves, Difficulty).
- **`recipe_code.py`**: Helper script for model training or data processing (assumed to contain related logic).
- **`requirements.txt`**: Python dependencies for the project.
- **`web_scraping.py`**: Script to scrape recipe data from BBC Good Food and create `bbcgoodfood_recipes2.json`.

## Dataset
The dataset (`bbcgoodfood_recipes2.json`) is generated by `web_scraping.py`, which scrapes BBC Good Food for recipes. Each recipe includes:
- **Title**: Recipe name (e.g., "Easy chocolate cake").
- **Image**: URL to recipe image.
- **Ingredients**: List of ingredients (e.g., ["200g golden caster sugar", "200g unsalted butter"]).
- **Method Steps**: Cooking instructions.
- **Prep Time**, **Cook Time**: Preparation and cooking durations.
- **Serves**: Number of servings.
- **Difficulty**: Easy, Medium, or Hard.

To update the dataset, run:
```bash
python web_scraping.py
```

## Model Training
The project uses a Keras neural network to rank recipes based on ingredient encodings:
- **Input**: Binary encoding of ingredients (1 if present, 0 if not).
- **Architecture**: Three layers (`Dense(16, relu)`, `Dense(8, relu)`, `Dense(1, sigmoid)`).
- **Training**: Uses 200 recipes, 3 epochs, batch size 64, with dummy binary labels for simplicity.
- **Output**: Saved as `recipe_model.h5`.

Training occurs in `app.py` (via "Train and Save Model" button) or `recipe_code.py` (if separate). To train manually:
```bash
python app.py  # Click "Train and Save Model" in UI
```
Or, if `recipe_code.py` contains training logic:
```bash
python recipe_code.py
```

The trained model can be pushed to GitHub using the "Push Model to GitHub" button, requiring a GitHub Personal Access Token (PAT).

## Installation
1. **Clone the Repository**:
   ```bash
   git clone https://github.com/your_username/your_repo.git
   cd your_repo
   ```

2. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Ensure Dataset**:
   - Verify `bbcgoodfood_recipes2.json` exists.
   - If missing, run:
     ```bash
     python web_scraping.py
     ```

4. **Optional: GitHub Setup**:
   - Create a PAT at GitHub > Settings > Developer settings > Personal access tokens.
   - Set environment variables:
     ```bash
     export GITHUB_TOKEN=your_pat
     export REPO_URL=https://github.com/your_username/your_repo.git
     ```

## Usage
1. **Run the Application**:
   ```bash
   streamlit run app.py
   ```
   Open `http://localhost:8501` in your browser.

2. **Generate Recipes**:
   - Enter ingredients (e.g., `sugar, butter`) in the sidebar.
   - Select difficulty (Easy, Medium, Hard).
   - Click "Generate Recipes".
   - View up to 3 recipe cards with bold labels (e.g., **Difficulty**: Easy) and an image.

3. **Train Model**:
   - Click "Train and Save Model" to train and save `recipe_model.h5`.
   - Expect ~2-5 minutes for training.

4. **Push Model to GitHub**:
   - Set `GITHUB_TOKEN` and `REPO_URL` environment variables.
   - Click "Push Model to GitHub" to upload `recipe_model.h5`.

## Contributing
Contributions are welcome! To contribute:
1. Fork the repository.
2. Create a branch: `git checkout -b feature-name`.
3. Commit changes: `git commit -m "Add feature"`.
4. Push: `git push origin feature-name`.
5. Open a pull request.

Please ensure code follows PEP 8 and includes tests where applicable.

## License
This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.